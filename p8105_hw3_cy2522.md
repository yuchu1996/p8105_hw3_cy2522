p8105\_hw3\_cy2522
================
Chu YU
2018-Oct-6

problem 1
=========

``` r
## import the data
library(p8105.datasets)
library(tidyverse)
```

    ## -- Attaching packages --------------------------------------- tidyverse 1.2.1 --

    ## √ ggplot2 3.0.0     √ purrr   0.2.5
    ## √ tibble  1.4.2     √ dplyr   0.7.6
    ## √ tidyr   0.8.1     √ stringr 1.3.1
    ## √ readr   1.1.1     √ forcats 0.3.0

    ## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
theme_set(theme_bw() + theme(legend.position = "right"))
data(brfss_smart2010)

## do some data cleaning
brfss_tidy = brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>%
  mutate(response = 
           factor(response, order = TRUE, levels = c("Excellent", "Very good", "Good", "Fair","Poor"))) 
```

the questions in problem 1
--------------------------

``` r
# answer the questions

## which state is observed at 7 locations:
filter(brfss_tidy, year == "2002") %>% 
  group_by(locationabbr) %>%
  summarize(n_location = n_distinct(locationdesc)) %>%
  filter(n_location == 7)
```

    ## # A tibble: 3 x 2
    ##   locationabbr n_location
    ##   <chr>             <int>
    ## 1 CT                    7
    ## 2 FL                    7
    ## 3 NC                    7

``` r
## number of observations in each state in different years
brfss_tidy %>% 
  group_by(year, locationabbr) %>%
  summarize(n_location = n_distinct(locationdesc)) %>%
  ggplot(aes(x = year, y = n_location, color = locationabbr)) +
  geom_line() +
  labs( 
    title = "spaghetti plot of observations in each state",
    x = "year",
    y = "number of locations")
```

![](p8105_hw3_cy2522_files/figure-markdown_github/unnamed-chunk-2-1.png)

``` r
## table for NY state
NY_table = filter(brfss_tidy , 
                  response == "Excellent" & locationabbr == "NY" & (year == "2002" | year == "2006"| year == "2010")) %>%
  group_by(year) %>%
  summarize(mean(data_value), sd(data_value)) %>%
  knitr::kable(digits = 3, col.names = c("year", "mean", "sd"), caption = "the form of Excellent response data in NY") 

NY_table
```

|  year|    mean|     sd|
|-----:|-------:|------:|
|  2002|  24.040|  4.486|
|  2006|  22.533|  4.001|
|  2010|  22.700|  3.567|

``` r
## 5-panel plots for each state and each year
brfss_tidy %>% 
  group_by(year, response, locationabbr) %>%
  summarize(mean = mean(data_value)) %>%
  ggplot(aes(x = year, y = mean)) +
           geom_point(alpha = .1) +
           facet_grid(. ~ response) +
            labs( 
    title = " plot of responses in each state over the years",
    x = "year",
    y = "mean of response proportion") +
   theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

    ## Warning: Removed 21 rows containing missing values (geom_point).

![](p8105_hw3_cy2522_files/figure-markdown_github/unnamed-chunk-2-2.png) Problem 1 answers: **1. cleaning the dataset:**

    - clean the names of the variables of the brfss data.

    - `filter` the topic so that there is only one topic "Overall Health"
    - use `mutate` function so that I can set the order of the factor response, from which I can also see delete the other seponses in the dataset.

\*\* 2. questions:\*\*

    - In 2002, **CT, FL, NC** were observed at 7 locations. 
    (After `group_by` and `summarize` we can get the number of observations of each state, then we can get the three states whose observations equal 7.)

    - We can see the plot named "spaghetti plot of observations in each state from 2002 to 2010" above. From the plot we can know that overall the states' observations are increasing. And we can also see the different tendency of observations of each state and the differences between them.

    - From the table shown above, from 2002 to 2010, the average of Excellent proportion in NY has been increasing, meanwhile the sd is getting smaller, meaning that the response value datae of Excellent is getting more stable.

    - In the plot we can get the different mean proportions of each state, x represents the different years, and y represents the mean proportions. We can know the distribution of the states and the overall situation of responses proportions nationwide.

problem 2
=========

``` r
## import the data
library(p8105.datasets)

data(instacart)

## exploration of the data
inst_tidy = instacart %>%
  janitor::clean_names()

 dim(inst_tidy)
```

    ## [1] 1384617      15

``` r
 str(inst_tidy)
```

    ## Classes 'tbl_df', 'tbl' and 'data.frame':    1384617 obs. of  15 variables:
    ##  $ order_id              : int  1 1 1 1 1 1 1 1 36 36 ...
    ##  $ product_id            : int  49302 11109 10246 49683 43633 13176 47209 22035 39612 19660 ...
    ##  $ add_to_cart_order     : int  1 2 3 4 5 6 7 8 1 2 ...
    ##  $ reordered             : int  1 1 0 0 1 0 0 1 0 1 ...
    ##  $ user_id               : int  112108 112108 112108 112108 112108 112108 112108 112108 79431 79431 ...
    ##  $ eval_set              : chr  "train" "train" "train" "train" ...
    ##  $ order_number          : int  4 4 4 4 4 4 4 4 23 23 ...
    ##  $ order_dow             : int  4 4 4 4 4 4 4 4 6 6 ...
    ##  $ order_hour_of_day     : int  10 10 10 10 10 10 10 10 18 18 ...
    ##  $ days_since_prior_order: int  9 9 9 9 9 9 9 9 30 30 ...
    ##  $ product_name          : chr  "Bulgarian Yogurt" "Organic 4% Milk Fat Whole Milk Cottage Cheese" "Organic Celery Hearts" "Cucumber Kirby" ...
    ##  $ aisle_id              : int  120 108 83 83 95 24 24 21 2 115 ...
    ##  $ department_id         : int  16 16 4 4 15 4 4 16 16 7 ...
    ##  $ aisle                 : chr  "yogurt" "other creams cheeses" "fresh vegetables" "fresh vegetables" ...
    ##  $ department            : chr  "dairy eggs" "dairy eggs" "produce" "produce" ...
    ##  - attr(*, "spec")=List of 2
    ##   ..$ cols   :List of 15
    ##   .. ..$ order_id              : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ product_id            : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ add_to_cart_order     : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ reordered             : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ user_id               : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ eval_set              : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
    ##   .. ..$ order_number          : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ order_dow             : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ order_hour_of_day     : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ days_since_prior_order: list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ product_name          : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
    ##   .. ..$ aisle_id              : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ department_id         : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ aisle                 : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
    ##   .. ..$ department            : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
    ##   ..$ default: list()
    ##   .. ..- attr(*, "class")= chr  "collector_guess" "collector"
    ##   ..- attr(*, "class")= chr "col_spec"

``` r
 n_distinct(inst_tidy$product_id) 
```

    ## [1] 39123

problem 2 \*\* 1. Exploration of the datasets\*\*

-   From the datasets, we can see the size is 1384617, 15, meaning there are 1384614 observations of 15 variables. Using `str()` we can get the overall struction of the data.

-   The variables in the dataset are characters and integers. The variable order\_id , product\_id, user\_id , add\_to\_cart\_order, reordered, order\_number, order\_dow , order\_hour\_of\_day, days\_since\_prior\_order, aisle\_id and department\_id are all integers, and there are character variables like eval\_set, product\_name, department and aisle.

-   We can know the meaning of some variables via the values and names of them -- the IDs of the products, users, departments and orders, the names of the products, the number of orders and so on. So from the data we can know that this may be the trading data from instacart. By using `n_distinct`, we can get the exact number of the orders and products and other things . For example, we can know there are 39123 products sold in the dataset.

**2. questions**

``` r
## How many aisles are there, and which aisles are the most items ordered from?

n_distinct(inst_tidy$aisle)
```

    ## [1] 134

``` r
names(table(inst_tidy$aisle))[which.max(table(inst_tidy$aisle))]
```

    ## [1] "fresh vegetables"

``` r
## Make a plot that shows the number of items ordered in each aisle. Order aisles sensibly, and organize your plot so others can read it.

inst_tidy %>%
  group_by(aisle) %>%
  summarise(n = n()) %>%
  ggplot(aes( y = n,x = reorder(aisle, n))) +
  geom_histogram(stat = "identity") +
  coord_flip() +
  labs( 
    title = " plot of aisles data",
    x = "aisle",
    y = "number")
```

    ## Warning: Ignoring unknown parameters: binwidth, bins, pad

![](p8105_hw3_cy2522_files/figure-markdown_github/unnamed-chunk-4-1.png)

``` r
## Make a table showing the most popular item aisles 

inst_tidy %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>%
  summarize(
    mostpop = names(table(product_name))[which.max(table(product_name))]) %>%
  knitr::kable(caption = "table of most popular items")
```

| aisle                      | mostpop                                       |
|:---------------------------|:----------------------------------------------|
| baking ingredients         | Light Brown Sugar                             |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |
| packaged vegetables fruits | Organic Baby Spinach                          |

``` r
## Make a table showing the mean hour of the day
 
inst_tidy %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean) %>%
  knitr::kable(digits = 3, caption = "the table of mean hour")
```

| product\_name    |       0|       1|       2|       3|       4|       5|       6|
|:-----------------|-------:|-------:|-------:|-------:|-------:|-------:|-------:|
| Coffee Ice Cream |  13.774|  14.316|  15.381|  15.318|  15.217|  12.263|  13.833|
| Pink Lady Apples |  13.441|  11.360|  11.702|  14.250|  11.552|  12.784|  11.938|

problem 2 **2. questions:** (1) How many aisles are there, and which aisles are the most items ordered from? - There are 134 distinct aisles, and most items ordered from "fresh vegetables".

1.  Make a plot that shows the number of items ordered in each aisle.

-   From the plot above, we can see the different number of products ordered in each aisle. Histogram can clearly present the differences between the amounts of each variable. And to be clearer, I use colors depend on the department. But the plot still need to be seen from a bigger window due to the large number of aisles.

1.  Make a table showing the most popular item from certain aisles.

-   The 3\*2 table has two variables -- "aisle" and "mostpop". From the table, we can know that:
-   In "baking ingredients" aisle, "Light Brown Sugar" is the most popular;
-   In "dog food care", "Snacks sticks Chicken & Rice Recipe Dog Treats" is the most popular;
-   In "packages vegetables fruits", "Organic Baby Spinach" is the most popular.

1.  Make a table showing the mean hour of the day:

-   I finally get a 2\*7 table. There are 7 key variables as column names -- from 0 to 6, and the row names are the names of the two products. The values are means of the hours of each day in a week.

Problem 3
=========

``` r
## import the data
data(ny_noaa)

## exploration of the data

 dim(ny_noaa)
```

    ## [1] 2595176       7

``` r
 str(ny_noaa)
```

    ## Classes 'tbl_df', 'tbl' and 'data.frame':    2595176 obs. of  7 variables:
    ##  $ id  : chr  "US1NYAB0001" "US1NYAB0001" "US1NYAB0001" "US1NYAB0001" ...
    ##  $ date: Date, format: "2007-11-01" "2007-11-02" ...
    ##  $ prcp: int  NA NA NA NA NA NA NA NA NA NA ...
    ##  $ snow: int  NA NA NA NA NA NA NA NA NA NA ...
    ##  $ snwd: int  NA NA NA NA NA NA NA NA NA NA ...
    ##  $ tmax: chr  NA NA NA NA ...
    ##  $ tmin: chr  NA NA NA NA ...
    ##  - attr(*, "spec")=List of 2
    ##   ..$ cols   :List of 7
    ##   .. ..$ id  : list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
    ##   .. ..$ date:List of 1
    ##   .. .. ..$ format: chr ""
    ##   .. .. ..- attr(*, "class")= chr  "collector_date" "collector"
    ##   .. ..$ prcp: list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ snow: list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ snwd: list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_integer" "collector"
    ##   .. ..$ tmax: list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
    ##   .. ..$ tmin: list()
    ##   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
    ##   ..$ default: list()
    ##   .. ..- attr(*, "class")= chr  "collector_guess" "collector"
    ##   ..- attr(*, "class")= chr "col_spec"

\*\* 1. Exploration of the datasets\*\*

-   From the datasets, we can see the size is 2595176 obs. of 7 variables. Using `str()` we can get the overall struction of the data.

-   The variables in the dataset are characters,integers and dates format. But from the str() results we can see that the head of the data frame are all missing values, which is hard to read. Id, tmax, tmin are characters, meanwhile prcp, snow and snwd are integers, date is Date format. There are some key variables like date (Date, format), prcp(integer), snow(integer), tmax (character) and so on. We can see the mode of every columns and know the meaning of them from the data. For example, the prcp,snow and snwd are three different weather. And there are temperatures on different dates. So we can know the data frame is a weather table of NY.

    -   Form the data frame , we can see that almost every row of "tmax" and "tmin" is missing value. There are 1000 missing values in both tmax and tmin. This is definitely an issue. I think when all values in a row are missing, it must impact others' understanding of the row. When someone can not tell what is a column or a row for from the values, the missing value is an issue and should be cleared.

problem 2 questions
-------------------

``` r
## Do some data cleaning. Create separate variables for year, month, and day.
noaa_tidy = ny_noaa %>% 
  janitor::clean_names() %>%
  separate(date, into = c("year", "month", "day"), sep = "-") %>%
  mutate(tmax = 0.1*as.numeric(tmax) , tmin = 0.1*as.numeric(tmin) )
  

## for snowfall
names(table(noaa_tidy$snow))[which.max(table(noaa_tidy$snow))]
```

    ## [1] "0"

``` r
## Make a two-panel plot showing the average temperature in January and in July in each station across years.

noaa_tidy %>%
  filter(month %in% c("01", "07")) %>%
  group_by(month, id, year) %>%
  summarize(average_tmax = mean(tmax, na.rm = T)) %>%
  ggplot(aes( x = year, y = average_tmax, fill = month)) +
  geom_boxplot() +
  facet_grid(month ~ .) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  labs( 
    title = " plot of average tmax",
    x = "year",
    y = "average tmax")
```

    ## Warning: Removed 5970 rows containing non-finite values (stat_boxplot).

![](p8105_hw3_cy2522_files/figure-markdown_github/unnamed-chunk-6-1.png)

``` r
## Make a two-panel plot showing (i) tmax vs tmin for the full dataset  
library(hexbin)
library(patchwork)

panel_1_temp = ggplot(noaa_tidy, aes(x = tmin, y = tmax)) +
  geom_hex()

panel_2_sonw = noaa_tidy %>% 
  filter(snow > 0 & snow < 100) %>%
  ggplot( aes(x = factor(year), y = snow)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

panel_1_temp + panel_2_sonw
```

    ## Warning: Removed 1136276 rows containing non-finite values (stat_binhex).

![](p8105_hw3_cy2522_files/figure-markdown_github/unnamed-chunk-6-2.png) **prblem 3- questions**

-   To give a reasonable units, I change the units of temperature to "degree centigrade". For snowfall, "0" is the most commonly observed value. It may because that New York only snows in winter, which is not that long.

Is there any observable / interpretable structure? Any outliers?

-   From the boxplot above, we can see that the tmax of Janury fluctuate mostly in interval of (-3, 5), and there are more outliers of higher temperature. The plots are skewed to the higher temperature. Compared with Janury, July has higher tmax average, around 27, and there are more outliers of lower tmperature. The plots are mostly skewed to lower temperature.

Make a two-panel plot

-   We can see from the first plot the relationship of tmax and tmin. And there are few extreme temperatures. From the second plot, we can see the boxplots skew to the higher snowfall.
